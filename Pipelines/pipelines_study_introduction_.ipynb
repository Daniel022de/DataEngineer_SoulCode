{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "1pnJ2Y4lm4mMsZ8KPT00vOy67kma07-nE",
      "authorship_tag": "ABX9TyMFL02dJM2Brg3GJHN/zP57",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Daniel022de/DataEnginner_SoulCode/blob/main/Pipelines/pipelines_study_introduction_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ðŸ“— **PIPELINE DE DADOS | CRIAÃ‡ÃƒO DE MODELOS**\n",
        "\n",
        "Esse Notebook Ã© referente as instruÃ§Ãµes feitas pelo professor **Igor Gondim** no bootcamp **engenharia de dados** da **SoulCode** na aula de introduÃ§Ã£o a automatizaÃ§Ã£o de processos atravÃ©s de ferramentas pipeline. A tecnologias escolhidas para consolidaÃ§Ã£o de conhecimento foi o Apache Beam e o DataFlow Google Cloud.\n",
        "\n",
        "\n",
        "\n",
        "! **VocÃª pode encontrar esse notebook no meu repositÃ³rio** [GitHub](https://github.com/Daniel022de/Bootcamp_SoulCode_EngenhariaDados)\n",
        "\n",
        "! **VocÃª pode entrar em contato comigo atravÃ©s do meu email** ddololiveira.pessoal@gmail.com **e** [Linkedin](https://www.linkedin.com/in/daniel-oliveira-503b0323b/).\n",
        "\n",
        "! **Toda dÃºvida,recomendaÃ§Ãµes e feedbacks serÃ£o bem-vindas.**\n",
        "\n"
      ],
      "metadata": {
        "id": "AtS6mmFqTor_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Importante destacar que a automaÃ§Ã£o de processos Ã© feita quando necessÃ¡ria em situaÃ§Ãµes corriqueiras**\n",
        "\n"
      ],
      "metadata": {
        "id": "8yg_17k3dYaY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*O que Ã© uma pipeline?*\n",
        "\n",
        "* Nada mais Ã© que um fluxo de trabalho. Um processo com comeÃ§o, meio e fim. Podendo ser manual (Usando Pandas/Pyspark por exemplo para processo de ETL) ou automatizada.\n",
        "\n",
        "* VÃ¡rias tecnologias criam pipelines.Exemplos:\n",
        "\n",
        "**airflow** (muito usado | codificado e visual | Todo processo Ã© executado na prÃ³pria ferramenta), **apache beam** (Cria o modelo que pode ser usado em qualquer nuvem | A execuÃ§Ã£o do modelo Ã© feito em nuvem),**apache hop** ...\n",
        "\n",
        "* O modelo nÃ£o Ã© eterno. SÃ£o necessÃ¡rias revisÃµes, pois os datasets podem mudar, por exemplo, posiÃ§Ãµes de colunas.\n"
      ],
      "metadata": {
        "id": "LZUlgH5SdtGH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#â–¶ 1   InstalaÃ§Ã£o"
      ],
      "metadata": {
        "id": "l-uRVFERh-K8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Realize cada uma em uma cÃ©lula diferente e reiniciando ambiente a cada pip."
      ],
      "metadata": {
        "id": "sLtRtNWblZpc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NUZtwKW5agKT"
      },
      "outputs": [],
      "source": [
        "# pip install --upgrade pip\n",
        "# pip install apache_beam[interactive]\n",
        "# pip install apache_beam[gcp]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install --upgrade pip"
      ],
      "metadata": {
        "id": "K_qcx68OVpYx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install apache_beam[interactive]"
      ],
      "metadata": {
        "id": "xR82Y8b2Vpu9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install apache_beam[gcp]"
      ],
      "metadata": {
        "id": "XsauF3EyVtpu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#â–¶ 2    ImportaÃ§Ã£o"
      ],
      "metadata": {
        "id": "mPwGXPJVl-zB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import apache_beam as beam"
      ],
      "metadata": {
        "id": "sP_6yIBIlggS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#â–¶ 3    Pipelines"
      ],
      "metadata": {
        "id": "_nYKNm9-WFIp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **voos** - Ã‰ o fluxo.\n",
        "\n",
        "* **|** - Passo\n",
        "\n",
        "* Os comandos precisam ter descriÃ§Ãµes\n",
        "\n",
        "* **skip_header_lines = 1** - Pula a primeira lista que geralmente sÃ£o os nomes das colunas, por padrÃ£o Ã© 0. Ã‰ necessÃ¡rio essa parte para que nÃ£o haja erros em somatÃ³rias,divisÃµes...\n",
        "\n",
        "* **|'Imprimir o resultado'>> beam.Map(print)** - FaÃ§a somente no arquivo final ou para visualizar, pois o comando print descarta o arquivo da memÃ³ria."
      ],
      "metadata": {
        "id": "IdG7yXIgmMGf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Colunas:**\n",
        "\n",
        "\n",
        "AIRLINE', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT', 'SCHEDULED_DEPARTURE', 'DEPARTURE_TIME', 'DEPARTURE_DELAY', 'TAXI_OUT', 'WHEELS_OFF', 'SCHEDULED_TIME', 'ELAPSED_TIME', 'AIR_TIME', 'DISTANCE', 'WHEELS_ON', 'TAXI_IN', 'SCHEDULED_ARRIVAL', 'ARRIVAL_TIME', 'ARRIVAL_DELAY', 'DIVERTED', 'CANCELLED'"
      ],
      "metadata": {
        "id": "3hl2MfZ3we7-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##â—¼ 3.1 Imprimir arquivo"
      ],
      "metadata": {
        "id": "d1f6V_mLZB-a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "p1 = beam.Pipeline()\n",
        "\n",
        "voos = (\n",
        "    p1\n",
        "    |'Extrair do CSV'>> beam.io.ReadFromText('/content/drive/MyDrive/DATASETS UPLOAD/voos.csv',skip_header_lines=1)\n",
        "    |'Separador de dados'>> beam.Map(lambda record: record.split(','))\n",
        "    |'Imprimir o resultado'>> beam.Map(print)\n",
        ")\n",
        "\n",
        "p1.run()"
      ],
      "metadata": {
        "id": "5fYJEVk5l59V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##â—¼ 3.2 Criar arquivo"
      ],
      "metadata": {
        "id": "g3KdyqZbx_Yl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "p1 = beam.Pipeline()\n",
        "\n",
        "criar = (\n",
        "      p1\n",
        "      |'Extrair CSV' >> beam.io.ReadFromText('/content/drive/MyDrive/DATASETS UPLOAD/voos.csv',skip_header_lines=1)\n",
        "      |'Separar os dados' >> beam.Map(lambda records: records.split(',')) \n",
        "      |'Criando arquivo' >> beam.io.WriteToText('arquivo.csv')\n",
        ")\n",
        "\n",
        "p1.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u1egzTArXz9F",
        "outputId": "22736fa6-3545-4efc-9e22-8e982cf15349"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<apache_beam.runners.portability.fn_api_runner.fn_runner.RunnerResult at 0x7f92805f3040>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##â—¼ 3.3 Filtros"
      ],
      "metadata": {
        "id": "SYKk1_aD3qSl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### â—¼ 3.3.1 Origem"
      ],
      "metadata": {
        "id": "un0bXKqTbO1e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "p1 = beam.Pipeline()\n",
        "\n",
        "filtro_origem = (\n",
        "      p1\n",
        "      |'Carregar CSV' >> beam.io.ReadFromText('/content/drive/MyDrive/DATASETS UPLOAD/voos.csv',skip_header_lines=1)\n",
        "      |'Separador dos dados' >> beam.Map(lambda records: records.split(','))\n",
        "      |'Filtro' >> beam.Filter(lambda records: records[1] == 'SFO')\n",
        "      |'Imprimir' >> beam.Map(print)\n",
        ")\n",
        "\n",
        "p1.run()"
      ],
      "metadata": {
        "id": "QSxUnE4bZYlF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### â—¼ 3.3.2  Saida atrasada"
      ],
      "metadata": {
        "id": "RforgcaibSpS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "p1 = beam.Pipeline()\n",
        "\n",
        "filtro_origem =(\n",
        "      p1\n",
        "      |'Carregar CSV' >> beam.io.ReadFromText('/content/drive/MyDrive/DATASETS UPLOAD/voos.csv',skip_header_lines=1)\n",
        "      |'Separador dos dados' >> beam.Map(lambda records: records.split(','))\n",
        "      |'Filtro' >> beam.Filter(lambda records: float(records[5]) > 0)\n",
        "      |'Imprimindo' >> beam.Map(print)\n",
        "\n",
        "      )\n",
        "p1.run()\n"
      ],
      "metadata": {
        "id": "OdGaji8hbab-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### â—¼ 3.3.3  Voos atrasados"
      ],
      "metadata": {
        "id": "Bwxr-4V0eHJS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "p1 = beam.Pipeline() \n",
        "\n",
        "voos = (\n",
        "    p1\n",
        "    |'Extrair do CSV'>> beam.io.ReadFromText('/content/drive/MyDrive/DATASETS UPLOAD/voos.csv',skip_header_lines=1)\n",
        "    |'Separador de dados'>> beam.Map(lambda record: record.split(','))\n",
        "    |'Filtro atraso'>> beam.Filter(lambda record: float(record[16]) > 0 )\n",
        "    |'Imprimir o resultado'>> beam.Map(print)\n",
        "  \n",
        ")\n",
        "\n",
        "p1.run()"
      ],
      "metadata": {
        "id": "TAIp4p6q_KcR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##â—¼ 3.4  Agrupamento"
      ],
      "metadata": {
        "id": "d0nEHLrgWc7E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Agrupamento minutos de atraso por aero\n",
        "\n",
        "p1 = beam.Pipeline() \n",
        "\n",
        "qtd_minuto = (\n",
        "    p1\n",
        "    |'Extrair do CSV'>> beam.io.ReadFromText('/content/drive/MyDrive/DATASETS UPLOAD/voos.csv',skip_header_lines=1)\n",
        "    |'Separador de dados'>> beam.Map(lambda record: record.split(','))\n",
        "    |'Filtro' >> beam.Filter(lambda record: float(record[16]) > 0)\n",
        "    |'Agrupamento' >> beam.Map(lambda record: (record[1],float(record[16])))\n",
        "    |'ConstruÃ§Ã£o da tabela atraso por minuto' >> beam.CombinePerKey(sum)\n",
        "    |'Imprimir' >> beam.Map(print)\n",
        ")\n",
        "p1.run()"
      ],
      "metadata": {
        "id": "BBLNgI-cepzE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Agrupamento de ocorrÃªncia de atraso por aero\n",
        "p1 = beam.Pipeline() \n",
        "\n",
        "qtd_ocorrencia = (\n",
        "    p1\n",
        "    |'Extrair do CSV'>> beam.io.ReadFromText('/content/drive/MyDrive/DATASETS UPLOAD/voos.csv',skip_header_lines=1)\n",
        "    |'Separador de dados'>> beam.Map(lambda record: record.split(','))\n",
        "    |'Filtro' >> beam.Filter(lambda record: float(record[16]) > 0)\n",
        "    |'Agrupamento' >> beam.Map(lambda record: (record[1],float(record[16])))\n",
        "    |'Criar tabela quantidade ocorrencia' >> beam.combiners.Count.PerKey()\n",
        "    |'Imprimir' >> beam.Map(print)\n",
        ")\n",
        "\n",
        "p1.run()\n"
      ],
      "metadata": {
        "id": "TetDC0y0fuQa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##â—¼ 3.5 coGroupBy"
      ],
      "metadata": {
        "id": "e4ZOAgXIbOkp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Criar nova tabela com dados agregados de duas pipelines\n",
        "\n",
        "p1 = beam.Pipeline() \n",
        "\n",
        "qtd_minuto = (\n",
        "    p1\n",
        "    |'Extrair DataSet'>> beam.io.ReadFromText('/content/drive/MyDrive/DATASETS UPLOAD/voos.csv',skip_header_lines=1)\n",
        "    |'SeparaÃ§Ã£o dos dados'>> beam.Map(lambda record: record.split(','))\n",
        "    |'Filtro minutos' >> beam.Filter(lambda record: float(record[16]) > 0)\n",
        "    |'Agrupamento dos dados' >> beam.Map(lambda record: (record[1],float(record[16])))\n",
        "    |'ConstruÃ§Ã£o da tabela atraso por minuto' >> beam.CombinePerKey(sum)\n",
        ")\n",
        "\n",
        "qtd_ocorrencia = (\n",
        "    p1\n",
        "    |'Extrair do CSV'>> beam.io.ReadFromText('/content/drive/MyDrive/DATASETS UPLOAD/voos.csv',skip_header_lines=1)\n",
        "    |'Separador de dados'>> beam.Map(lambda record: record.split(','))\n",
        "    |'Filtro' >> beam.Filter(lambda record: float(record[16]) > 0)\n",
        "    |'Agrupamento' >> beam.Map(lambda record: (record[1],float(record[16])))\n",
        "    |'Criar tabela quantidade ocorrencia' >> beam.combiners.Count.PerKey()\n",
        ")\n",
        "\n",
        "tabela = (\n",
        "    {'qtd_ocorrencia':qtd_ocorrencia,'qtd_minuto':qtd_minuto}\n",
        "    |'Unindo pernas' >> beam.CoGroupByKey()\n",
        "    |'Print' >> beam.Map(print)\n",
        ")\n",
        "\n",
        "\n",
        "p1.run()"
      ],
      "metadata": {
        "id": "i2Ne8evSirCv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#â–¶ 6    CriaÃ§Ã£o de model para GCP"
      ],
      "metadata": {
        "id": "58-pVOOWnvFc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import apache_beam\n",
        "import os\n",
        "from apache_beam.options.pipeline_options import PipelineOptions\n",
        "\n",
        "\n",
        "serviceAccount= '/content/drive/MyDrive/ACESSO A GCP/bc26-aulas-7791d7a8a1e0.json'\n",
        "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = serviceAccount\n",
        "\n",
        "\n",
        "pipeline_options = {\n",
        "    \n",
        "    'project':'bc26-aulas',\n",
        "    'runner':'DataflowRunner',\n",
        "    'region':'southamerica-east1',\n",
        "    'staging_location':'gs://ed7-datasets/staging/',\n",
        "    'temp_location':'gs://ed7-datasets/temp/',\n",
        "    'template_location':'gs://ed7-datasets/models/modelo_batch'\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "pipeline_options = PipelineOptions.from_dictionary(pipeline_options)\n",
        "\n",
        "p1 = beam.Pipeline(options = pipeline_options)\n",
        "\n",
        "qte_tempo = (\n",
        "    p1\n",
        "    |'Extrair do CSV'>> beam.io.ReadFromText('gs://ed7-datasets/brutos/voos.csv',skip_header_lines=1)\n",
        "    |'Separador de dados'>> beam.Map(lambda record: record.split(','))\n",
        "    |'Filtro atraso'>> beam.Filter(lambda record: float(record[16]) > 0 )\n",
        "    |'Agregar as colunas' >> beam.Map(lambda record: (record[1],float(record[16])))\n",
        "    |'Construir tabela por minuto somados' >> beam.CombinePerKey(sum)\n",
        "\n",
        ")\n",
        "\n",
        "qte_ocor = (\n",
        "    p1\n",
        "    |'Abrir do CSV'>> beam.io.ReadFromText('gs://ed7-datasets/brutos/voos.csv',skip_header_lines=1)\n",
        "    |'Separar por virgula'>> beam.Map(lambda record: record.split(','))\n",
        "    |'Filtro  aero atraso'>> beam.Filter(lambda record: float(record[16]) > 0 )\n",
        "    |'Juntar as colunas' >> beam.Map(lambda record: (record[1],float(record[16])))\n",
        "    |'Construir tabela por ocorrencia' >> beam.combiners.Count.PerKey()\n",
        "\n",
        ")\n",
        "\n",
        "tabela = (\n",
        "    {'Num_de_Ocorrencias':qte_ocor,'Quant_minutos':qte_tempo}\n",
        "    |'Agrupar as pernas' >> beam.CoGroupByKey()\n",
        "    |'Load final' >> beam.io.WriteToText('gs://ed7-datasets/tratados/voosatr',file_name_suffix='.csv')\n",
        "\n",
        "\n",
        ")\n",
        "\n",
        "p1.run()"
      ],
      "metadata": {
        "id": "uNuWKl32nxns"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}